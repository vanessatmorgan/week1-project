{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc121467-c6d7-4cf1-8904-c8eab246b984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping non-numeric columns: ['sex', 'race', 'ethnicity', 'handedness', 'participant_education', 'parent_1_education', 'parent_2_education']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd                  # for tabular data handling\n",
    "from pathlib import Path             # for handling filesystem paths\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"./DKTatlas_ThickAvg.csv\")\n",
    "# 2. Drop non-numeric\n",
    "numeric = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "drop_cols = [c for c in data.columns if c not in numeric]\n",
    "if drop_cols:\n",
    "    print(\"Dropping non-numeric columns:\", drop_cols)\n",
    "data = data[numeric]\n",
    "# 2. Drop non-numeric\n",
    "numeric = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "drop_cols = [c for c in data.columns if c not in numeric]\n",
    "if drop_cols:\n",
    "    print(\"Dropping non-numeric columns:\", drop_cols)\n",
    "data = data[numeric]\n",
    "\n",
    "\n",
    "train_data = data[data['p_factor'].notna()]\n",
    "test_data  = data[data['p_factor'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "030adb29-e80a-4183-8a48-b4f81133807c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>p_factor</th>\n",
       "      <th>lh_aparc_DKTatlas_caudalanteriorcingulate_ThickAvg</th>\n",
       "      <th>lh_aparc_DKTatlas_caudalmiddlefrontal_ThickAvg</th>\n",
       "      <th>lh_aparc_DKTatlas_cuneus_ThickAvg</th>\n",
       "      <th>lh_aparc_DKTatlas_entorhinal_ThickAvg</th>\n",
       "      <th>lh_aparc_DKTatlas_fusiform_ThickAvg</th>\n",
       "      <th>lh_aparc_DKTatlas_inferiorparietal_ThickAvg</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_aparc_DKTatlas_rostralanteriorcingulate_ThickAvg</th>\n",
       "      <th>rh_aparc_DKTatlas_rostralmiddlefrontal_ThickAvg</th>\n",
       "      <th>rh_aparc_DKTatlas_superiorfrontal_ThickAvg</th>\n",
       "      <th>rh_aparc_DKTatlas_superiorparietal_ThickAvg</th>\n",
       "      <th>rh_aparc_DKTatlas_superiortemporal_ThickAvg</th>\n",
       "      <th>rh_aparc_DKTatlas_supramarginal_ThickAvg</th>\n",
       "      <th>rh_aparc_DKTatlas_transversetemporal_ThickAvg</th>\n",
       "      <th>rh_aparc_DKTatlas_insula_ThickAvg</th>\n",
       "      <th>lh_aparc_DKTatlas_frontalpole_ThickAvg</th>\n",
       "      <th>rh_aparc_DKTatlas_temporalpole_ThickAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000393599</td>\n",
       "      <td>15.583333</td>\n",
       "      <td>22.15</td>\n",
       "      <td>0.589907</td>\n",
       "      <td>2.870</td>\n",
       "      <td>2.882</td>\n",
       "      <td>2.019</td>\n",
       "      <td>3.655</td>\n",
       "      <td>2.738</td>\n",
       "      <td>2.573</td>\n",
       "      <td>...</td>\n",
       "      <td>2.882</td>\n",
       "      <td>2.702</td>\n",
       "      <td>2.896</td>\n",
       "      <td>2.381</td>\n",
       "      <td>3.113</td>\n",
       "      <td>2.792</td>\n",
       "      <td>2.658</td>\n",
       "      <td>3.238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001970838</td>\n",
       "      <td>17.833333</td>\n",
       "      <td>23.98</td>\n",
       "      <td>-0.659061</td>\n",
       "      <td>2.751</td>\n",
       "      <td>2.788</td>\n",
       "      <td>2.053</td>\n",
       "      <td>3.273</td>\n",
       "      <td>2.638</td>\n",
       "      <td>2.413</td>\n",
       "      <td>...</td>\n",
       "      <td>2.795</td>\n",
       "      <td>2.680</td>\n",
       "      <td>2.864</td>\n",
       "      <td>2.188</td>\n",
       "      <td>3.084</td>\n",
       "      <td>2.587</td>\n",
       "      <td>2.462</td>\n",
       "      <td>3.114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007995238</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>23.77</td>\n",
       "      <td>-1.608375</td>\n",
       "      <td>2.789</td>\n",
       "      <td>2.853</td>\n",
       "      <td>2.053</td>\n",
       "      <td>3.529</td>\n",
       "      <td>2.952</td>\n",
       "      <td>2.734</td>\n",
       "      <td>...</td>\n",
       "      <td>2.797</td>\n",
       "      <td>2.624</td>\n",
       "      <td>2.870</td>\n",
       "      <td>2.530</td>\n",
       "      <td>3.092</td>\n",
       "      <td>2.854</td>\n",
       "      <td>2.529</td>\n",
       "      <td>3.438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1011497669</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>29.68</td>\n",
       "      <td>-1.233807</td>\n",
       "      <td>2.783</td>\n",
       "      <td>2.894</td>\n",
       "      <td>2.014</td>\n",
       "      <td>3.761</td>\n",
       "      <td>2.792</td>\n",
       "      <td>2.653</td>\n",
       "      <td>...</td>\n",
       "      <td>2.946</td>\n",
       "      <td>2.687</td>\n",
       "      <td>2.867</td>\n",
       "      <td>2.307</td>\n",
       "      <td>2.992</td>\n",
       "      <td>2.822</td>\n",
       "      <td>2.507</td>\n",
       "      <td>3.179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017092387</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>23.24</td>\n",
       "      <td>-0.923100</td>\n",
       "      <td>2.765</td>\n",
       "      <td>2.931</td>\n",
       "      <td>1.930</td>\n",
       "      <td>3.265</td>\n",
       "      <td>2.575</td>\n",
       "      <td>2.487</td>\n",
       "      <td>...</td>\n",
       "      <td>3.282</td>\n",
       "      <td>2.725</td>\n",
       "      <td>3.036</td>\n",
       "      <td>2.279</td>\n",
       "      <td>2.934</td>\n",
       "      <td>2.688</td>\n",
       "      <td>2.439</td>\n",
       "      <td>3.197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>983504031</td>\n",
       "      <td>16.083333</td>\n",
       "      <td>22.81</td>\n",
       "      <td>-1.262053</td>\n",
       "      <td>3.162</td>\n",
       "      <td>2.734</td>\n",
       "      <td>1.878</td>\n",
       "      <td>3.802</td>\n",
       "      <td>2.829</td>\n",
       "      <td>2.582</td>\n",
       "      <td>...</td>\n",
       "      <td>3.013</td>\n",
       "      <td>2.689</td>\n",
       "      <td>2.886</td>\n",
       "      <td>2.391</td>\n",
       "      <td>3.109</td>\n",
       "      <td>2.686</td>\n",
       "      <td>2.604</td>\n",
       "      <td>3.313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>985910486</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>24.50</td>\n",
       "      <td>-1.233807</td>\n",
       "      <td>3.037</td>\n",
       "      <td>2.969</td>\n",
       "      <td>2.047</td>\n",
       "      <td>3.275</td>\n",
       "      <td>2.678</td>\n",
       "      <td>2.497</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479</td>\n",
       "      <td>2.560</td>\n",
       "      <td>2.854</td>\n",
       "      <td>2.298</td>\n",
       "      <td>2.964</td>\n",
       "      <td>2.657</td>\n",
       "      <td>2.248</td>\n",
       "      <td>3.032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>986035435</td>\n",
       "      <td>9.916667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.872749</td>\n",
       "      <td>3.067</td>\n",
       "      <td>2.787</td>\n",
       "      <td>2.152</td>\n",
       "      <td>3.350</td>\n",
       "      <td>2.719</td>\n",
       "      <td>2.791</td>\n",
       "      <td>...</td>\n",
       "      <td>3.194</td>\n",
       "      <td>2.682</td>\n",
       "      <td>2.932</td>\n",
       "      <td>2.424</td>\n",
       "      <td>3.080</td>\n",
       "      <td>2.834</td>\n",
       "      <td>2.800</td>\n",
       "      <td>3.477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>993394555</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.420477</td>\n",
       "      <td>2.905</td>\n",
       "      <td>2.783</td>\n",
       "      <td>2.132</td>\n",
       "      <td>3.127</td>\n",
       "      <td>2.768</td>\n",
       "      <td>2.661</td>\n",
       "      <td>...</td>\n",
       "      <td>2.837</td>\n",
       "      <td>2.582</td>\n",
       "      <td>2.844</td>\n",
       "      <td>2.422</td>\n",
       "      <td>3.114</td>\n",
       "      <td>2.910</td>\n",
       "      <td>2.430</td>\n",
       "      <td>3.102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>997818717</td>\n",
       "      <td>20.916667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.088511</td>\n",
       "      <td>2.700</td>\n",
       "      <td>2.472</td>\n",
       "      <td>2.135</td>\n",
       "      <td>3.166</td>\n",
       "      <td>2.753</td>\n",
       "      <td>2.619</td>\n",
       "      <td>...</td>\n",
       "      <td>2.998</td>\n",
       "      <td>2.559</td>\n",
       "      <td>2.806</td>\n",
       "      <td>2.313</td>\n",
       "      <td>2.967</td>\n",
       "      <td>2.720</td>\n",
       "      <td>2.429</td>\n",
       "      <td>3.149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1067 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      participant_id        age    bmi  p_factor  \\\n",
       "0         1000393599  15.583333  22.15  0.589907   \n",
       "1         1001970838  17.833333  23.98 -0.659061   \n",
       "2         1007995238  13.750000  23.77 -1.608375   \n",
       "3         1011497669  16.666667  29.68 -1.233807   \n",
       "4         1017092387  18.666667  23.24 -0.923100   \n",
       "...              ...        ...    ...       ...   \n",
       "1062       983504031  16.083333  22.81 -1.262053   \n",
       "1063       985910486  18.750000  24.50 -1.233807   \n",
       "1064       986035435   9.916667    NaN -0.872749   \n",
       "1065       993394555  19.500000    NaN -1.420477   \n",
       "1066       997818717  20.916667    NaN  1.088511   \n",
       "\n",
       "      lh_aparc_DKTatlas_caudalanteriorcingulate_ThickAvg  \\\n",
       "0                                                 2.870    \n",
       "1                                                 2.751    \n",
       "2                                                 2.789    \n",
       "3                                                 2.783    \n",
       "4                                                 2.765    \n",
       "...                                                 ...    \n",
       "1062                                              3.162    \n",
       "1063                                              3.037    \n",
       "1064                                              3.067    \n",
       "1065                                              2.905    \n",
       "1066                                              2.700    \n",
       "\n",
       "      lh_aparc_DKTatlas_caudalmiddlefrontal_ThickAvg  \\\n",
       "0                                              2.882   \n",
       "1                                              2.788   \n",
       "2                                              2.853   \n",
       "3                                              2.894   \n",
       "4                                              2.931   \n",
       "...                                              ...   \n",
       "1062                                           2.734   \n",
       "1063                                           2.969   \n",
       "1064                                           2.787   \n",
       "1065                                           2.783   \n",
       "1066                                           2.472   \n",
       "\n",
       "      lh_aparc_DKTatlas_cuneus_ThickAvg  \\\n",
       "0                                 2.019   \n",
       "1                                 2.053   \n",
       "2                                 2.053   \n",
       "3                                 2.014   \n",
       "4                                 1.930   \n",
       "...                                 ...   \n",
       "1062                              1.878   \n",
       "1063                              2.047   \n",
       "1064                              2.152   \n",
       "1065                              2.132   \n",
       "1066                              2.135   \n",
       "\n",
       "      lh_aparc_DKTatlas_entorhinal_ThickAvg  \\\n",
       "0                                     3.655   \n",
       "1                                     3.273   \n",
       "2                                     3.529   \n",
       "3                                     3.761   \n",
       "4                                     3.265   \n",
       "...                                     ...   \n",
       "1062                                  3.802   \n",
       "1063                                  3.275   \n",
       "1064                                  3.350   \n",
       "1065                                  3.127   \n",
       "1066                                  3.166   \n",
       "\n",
       "      lh_aparc_DKTatlas_fusiform_ThickAvg  \\\n",
       "0                                   2.738   \n",
       "1                                   2.638   \n",
       "2                                   2.952   \n",
       "3                                   2.792   \n",
       "4                                   2.575   \n",
       "...                                   ...   \n",
       "1062                                2.829   \n",
       "1063                                2.678   \n",
       "1064                                2.719   \n",
       "1065                                2.768   \n",
       "1066                                2.753   \n",
       "\n",
       "      lh_aparc_DKTatlas_inferiorparietal_ThickAvg  ...  \\\n",
       "0                                           2.573  ...   \n",
       "1                                           2.413  ...   \n",
       "2                                           2.734  ...   \n",
       "3                                           2.653  ...   \n",
       "4                                           2.487  ...   \n",
       "...                                           ...  ...   \n",
       "1062                                        2.582  ...   \n",
       "1063                                        2.497  ...   \n",
       "1064                                        2.791  ...   \n",
       "1065                                        2.661  ...   \n",
       "1066                                        2.619  ...   \n",
       "\n",
       "      rh_aparc_DKTatlas_rostralanteriorcingulate_ThickAvg  \\\n",
       "0                                                 2.882     \n",
       "1                                                 2.795     \n",
       "2                                                 2.797     \n",
       "3                                                 2.946     \n",
       "4                                                 3.282     \n",
       "...                                                 ...     \n",
       "1062                                              3.013     \n",
       "1063                                              2.479     \n",
       "1064                                              3.194     \n",
       "1065                                              2.837     \n",
       "1066                                              2.998     \n",
       "\n",
       "      rh_aparc_DKTatlas_rostralmiddlefrontal_ThickAvg  \\\n",
       "0                                               2.702   \n",
       "1                                               2.680   \n",
       "2                                               2.624   \n",
       "3                                               2.687   \n",
       "4                                               2.725   \n",
       "...                                               ...   \n",
       "1062                                            2.689   \n",
       "1063                                            2.560   \n",
       "1064                                            2.682   \n",
       "1065                                            2.582   \n",
       "1066                                            2.559   \n",
       "\n",
       "      rh_aparc_DKTatlas_superiorfrontal_ThickAvg  \\\n",
       "0                                          2.896   \n",
       "1                                          2.864   \n",
       "2                                          2.870   \n",
       "3                                          2.867   \n",
       "4                                          3.036   \n",
       "...                                          ...   \n",
       "1062                                       2.886   \n",
       "1063                                       2.854   \n",
       "1064                                       2.932   \n",
       "1065                                       2.844   \n",
       "1066                                       2.806   \n",
       "\n",
       "      rh_aparc_DKTatlas_superiorparietal_ThickAvg  \\\n",
       "0                                           2.381   \n",
       "1                                           2.188   \n",
       "2                                           2.530   \n",
       "3                                           2.307   \n",
       "4                                           2.279   \n",
       "...                                           ...   \n",
       "1062                                        2.391   \n",
       "1063                                        2.298   \n",
       "1064                                        2.424   \n",
       "1065                                        2.422   \n",
       "1066                                        2.313   \n",
       "\n",
       "      rh_aparc_DKTatlas_superiortemporal_ThickAvg  \\\n",
       "0                                           3.113   \n",
       "1                                           3.084   \n",
       "2                                           3.092   \n",
       "3                                           2.992   \n",
       "4                                           2.934   \n",
       "...                                           ...   \n",
       "1062                                        3.109   \n",
       "1063                                        2.964   \n",
       "1064                                        3.080   \n",
       "1065                                        3.114   \n",
       "1066                                        2.967   \n",
       "\n",
       "      rh_aparc_DKTatlas_supramarginal_ThickAvg  \\\n",
       "0                                        2.792   \n",
       "1                                        2.587   \n",
       "2                                        2.854   \n",
       "3                                        2.822   \n",
       "4                                        2.688   \n",
       "...                                        ...   \n",
       "1062                                     2.686   \n",
       "1063                                     2.657   \n",
       "1064                                     2.834   \n",
       "1065                                     2.910   \n",
       "1066                                     2.720   \n",
       "\n",
       "      rh_aparc_DKTatlas_transversetemporal_ThickAvg  \\\n",
       "0                                             2.658   \n",
       "1                                             2.462   \n",
       "2                                             2.529   \n",
       "3                                             2.507   \n",
       "4                                             2.439   \n",
       "...                                             ...   \n",
       "1062                                          2.604   \n",
       "1063                                          2.248   \n",
       "1064                                          2.800   \n",
       "1065                                          2.430   \n",
       "1066                                          2.429   \n",
       "\n",
       "      rh_aparc_DKTatlas_insula_ThickAvg  \\\n",
       "0                                 3.238   \n",
       "1                                 3.114   \n",
       "2                                 3.438   \n",
       "3                                 3.179   \n",
       "4                                 3.197   \n",
       "...                                 ...   \n",
       "1062                              3.313   \n",
       "1063                              3.032   \n",
       "1064                              3.477   \n",
       "1065                              3.102   \n",
       "1066                              3.149   \n",
       "\n",
       "      lh_aparc_DKTatlas_frontalpole_ThickAvg  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "...                                      ...   \n",
       "1062                                     NaN   \n",
       "1063                                     NaN   \n",
       "1064                                     NaN   \n",
       "1065                                     NaN   \n",
       "1066                                     NaN   \n",
       "\n",
       "      rh_aparc_DKTatlas_temporalpole_ThickAvg  \n",
       "0                                         NaN  \n",
       "1                                         NaN  \n",
       "2                                         NaN  \n",
       "3                                         NaN  \n",
       "4                                         NaN  \n",
       "...                                       ...  \n",
       "1062                                      NaN  \n",
       "1063                                      NaN  \n",
       "1064                                      NaN  \n",
       "1065                                      NaN  \n",
       "1066                                      NaN  \n",
       "\n",
       "[1067 rows x 68 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd4b737c-8e53-4364-9ea7-01d7a31653c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum p_factor: -1.608374501\n",
      "Number of subjects with min value: 177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Remove subjects at the minimum p_factor value and plot distributions\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Plot histogram of p_factor for all training subjects\n",
    "#train_data[\"p_factor\"].hist(bins=100)\n",
    "\n",
    "# Print minimum value and its count\n",
    "print(\"Minimum p_factor:\", train_data[\"p_factor\"].min())\n",
    "print(\"Number of subjects with min value:\",\n",
    "      train_data[\"p_factor\"].value_counts()[train_data[\"p_factor\"].min()])\n",
    "\n",
    "# Remove subjects with minimum p_factor (to avoid bias in modeling)\n",
    "min_val_idx = train_data[\"p_factor\"] == train_data[\"p_factor\"].min()\n",
    "removed_train_data = train_data[min_val_idx].copy()\n",
    "clean_train_data   = train_data[~min_val_idx]\n",
    "\n",
    "# Plot histogram after cleaning\n",
    "clean_train_data[\"p_factor\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "040e5635-4c3f-4546-ac76-a85c6e5979e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns with >50% missing: ['lh_aparc_DKTatlas_frontalpole_ThickAvg', 'rh_aparc_DKTatlas_temporalpole_ThickAvg']\n",
      "              model     r2   rmse    mae\n",
      "0               SVR  0.020  0.788  0.634\n",
      "1      RandomForest  0.028  0.785  0.650\n",
      "2  LinearRegression -0.068  0.822  0.680\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# 1. Prepare data\n",
    "train_data = data[data['p_factor'].notna()].copy()\n",
    "\n",
    "# 1a. Remove subjects with minimum p_factor\n",
    "min_val = train_data['p_factor'].min()\n",
    "min_idx = train_data['p_factor'] == min_val\n",
    "removed = train_data[min_idx].copy()\n",
    "clean   = train_data[~min_idx].copy()\n",
    "\n",
    "# 2. Define X and y\n",
    "X = clean.drop(columns=['p_factor'])\n",
    "y = clean['p_factor']\n",
    "\n",
    "# 3. Drop non-numeric columns\n",
    "numeric_cols      = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "non_numeric_cols  = [c for c in X.columns if c not in numeric_cols]\n",
    "if non_numeric_cols:\n",
    "    print('Dropping non-numeric columns:', non_numeric_cols)\n",
    "X = X[numeric_cols]\n",
    "\n",
    "# 4. Drop columns with >50% missing\n",
    "missing_frac = X.isna().mean()\n",
    "to_drop      = missing_frac[missing_frac > 0.5].index.tolist()\n",
    "if to_drop:\n",
    "    print('Dropping columns with >50% missing:', to_drop)\n",
    "X = X.drop(columns=to_drop)\n",
    "\n",
    "# 5. Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 6. Cross-validation strategy (for hyperparameter tuning if needed)\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "# 7. Define regression models\n",
    "models = {\n",
    "    'SVR': SVR(kernel='rbf'),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'LinearRegression': LinearRegression()\n",
    "}\n",
    "\n",
    "# 8. Train, predict, evaluate\n",
    "results = []\n",
    "for name, reg in models.items():\n",
    "    pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # fill NaNs\n",
    "        ('scaler',   StandardScaler()),               # standardize\n",
    "        ('pca',      PCA(n_components=0.95)),         # keep 95% variance\n",
    "        ('reg',      reg)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    # compute regression metrics\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "    mse  = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        'model': name,\n",
    "        'r2':    round(r2,   3),\n",
    "        'rmse': round(rmse, 3),\n",
    "        'mae':  round(mae,  3)\n",
    "    })\n",
    "\n",
    "# 9. Summarize results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
