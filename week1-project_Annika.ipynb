{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3270dc9c",
   "metadata": {},
   "source": [
    "# RBC Loading & Modeling Template\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "\n",
    "1. Load participant metadata from the Reproducible Brain Charts (RBC).  \n",
    "2. Retrieve FreeSurfer region-surface stats for participants.  \n",
    "3. Clean and filter data.  \n",
    "4. Plot simple histograms of the target variable.  \n",
    "5. Prepare a subset of subjects and features for modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1e3b6",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf2c98db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Imports\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "from pathlib import Path             # for handling filesystem paths\n",
    "import re                            # for regex string cleaning\n",
    "import numpy as np                   # for numeric operations\n",
    "import pandas as pd                  # for tabular data handling\n",
    "from rbclib import RBCPath           # RBC-specific path handling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac25bd9c",
   "metadata": {},
   "source": [
    "### Data paths & participant metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b4b4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>study</th>\n",
       "      <th>study_site</th>\n",
       "      <th>session_id</th>\n",
       "      <th>wave</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>bmi</th>\n",
       "      <th>handedness</th>\n",
       "      <th>participant_education</th>\n",
       "      <th>parent_1_education</th>\n",
       "      <th>parent_2_education</th>\n",
       "      <th>p_factor</th>\n",
       "      <th>internalizing_mcelroy_harmonized_all_samples</th>\n",
       "      <th>externalizing_mcelroy_harmonized_all_samples</th>\n",
       "      <th>attention_mcelroy_harmonized_all_samples</th>\n",
       "      <th>cubids_acquisition_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000393599</td>\n",
       "      <td>PNC</td>\n",
       "      <td>PNC1</td>\n",
       "      <td>PNC1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.583333</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>not Hispanic or Latino</td>\n",
       "      <td>22.15</td>\n",
       "      <td>Right</td>\n",
       "      <td>9th Grade</td>\n",
       "      <td>Complete primary</td>\n",
       "      <td>Complete secondary</td>\n",
       "      <td>0.589907</td>\n",
       "      <td>-0.449373</td>\n",
       "      <td>-0.630780</td>\n",
       "      <td>-1.842178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001970838</td>\n",
       "      <td>PNC</td>\n",
       "      <td>PNC1</td>\n",
       "      <td>PNC1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.833333</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>23.98</td>\n",
       "      <td>Right</td>\n",
       "      <td>11th Grade</td>\n",
       "      <td>Complete tertiary</td>\n",
       "      <td>Complete tertiary</td>\n",
       "      <td>-0.659061</td>\n",
       "      <td>0.531072</td>\n",
       "      <td>0.392751</td>\n",
       "      <td>0.190706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007995238</td>\n",
       "      <td>PNC</td>\n",
       "      <td>PNC1</td>\n",
       "      <td>PNC1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>Female</td>\n",
       "      <td>Other</td>\n",
       "      <td>not Hispanic or Latino</td>\n",
       "      <td>23.77</td>\n",
       "      <td>Right</td>\n",
       "      <td>6th Grade</td>\n",
       "      <td>Complete tertiary</td>\n",
       "      <td>Complete primary</td>\n",
       "      <td>-1.608375</td>\n",
       "      <td>-0.744118</td>\n",
       "      <td>-0.314187</td>\n",
       "      <td>-0.432662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1011497669</td>\n",
       "      <td>PNC</td>\n",
       "      <td>PNC1</td>\n",
       "      <td>PNC1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>not Hispanic or Latino</td>\n",
       "      <td>29.68</td>\n",
       "      <td>Right</td>\n",
       "      <td>9th Grade</td>\n",
       "      <td>Complete tertiary</td>\n",
       "      <td>Complete tertiary</td>\n",
       "      <td>-1.233807</td>\n",
       "      <td>-0.896835</td>\n",
       "      <td>-0.449099</td>\n",
       "      <td>0.111167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017092387</td>\n",
       "      <td>PNC</td>\n",
       "      <td>PNC1</td>\n",
       "      <td>PNC1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>not Hispanic or Latino</td>\n",
       "      <td>23.24</td>\n",
       "      <td>Right</td>\n",
       "      <td>11th Grade</td>\n",
       "      <td>Complete primary</td>\n",
       "      <td>Complete primary</td>\n",
       "      <td>-0.923100</td>\n",
       "      <td>-0.313455</td>\n",
       "      <td>2.204168</td>\n",
       "      <td>-0.782266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id study study_site session_id  wave        age     sex   race  \\\n",
       "0      1000393599   PNC       PNC1       PNC1     1  15.583333    Male  Black   \n",
       "1      1001970838   PNC       PNC1       PNC1     1  17.833333    Male  Other   \n",
       "2      1007995238   PNC       PNC1       PNC1     1  13.750000  Female  Other   \n",
       "3      1011497669   PNC       PNC1       PNC1     1  16.666667    Male  White   \n",
       "4      1017092387   PNC       PNC1       PNC1     1  18.666667  Female  Black   \n",
       "\n",
       "                ethnicity    bmi handedness participant_education  \\\n",
       "0  not Hispanic or Latino  22.15      Right             9th Grade   \n",
       "1      Hispanic or Latino  23.98      Right            11th Grade   \n",
       "2  not Hispanic or Latino  23.77      Right             6th Grade   \n",
       "3  not Hispanic or Latino  29.68      Right             9th Grade   \n",
       "4  not Hispanic or Latino  23.24      Right            11th Grade   \n",
       "\n",
       "  parent_1_education  parent_2_education  p_factor  \\\n",
       "0   Complete primary  Complete secondary  0.589907   \n",
       "1  Complete tertiary   Complete tertiary -0.659061   \n",
       "2  Complete tertiary    Complete primary -1.608375   \n",
       "3  Complete tertiary   Complete tertiary -1.233807   \n",
       "4   Complete primary    Complete primary -0.923100   \n",
       "\n",
       "   internalizing_mcelroy_harmonized_all_samples  \\\n",
       "0                                     -0.449373   \n",
       "1                                      0.531072   \n",
       "2                                     -0.744118   \n",
       "3                                     -0.896835   \n",
       "4                                     -0.313455   \n",
       "\n",
       "   externalizing_mcelroy_harmonized_all_samples  \\\n",
       "0                                     -0.630780   \n",
       "1                                      0.392751   \n",
       "2                                     -0.314187   \n",
       "3                                     -0.449099   \n",
       "4                                      2.204168   \n",
       "\n",
       "   attention_mcelroy_harmonized_all_samples  cubids_acquisition_group  \n",
       "0                                 -1.842178                         1  \n",
       "1                                  0.190706                         1  \n",
       "2                                 -0.432662                         1  \n",
       "3                                  0.111167                         1  \n",
       "4                                 -0.782266                         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Paths to the RBC data\n",
    "# ---------------------------------------------------------------------------\n",
    "rbcdata_path = Path(\"/home/jovyan/shared/data/RBC\")\n",
    "train_filepath = rbcdata_path / \"train_participants.tsv\"\n",
    "test_filepath  = rbcdata_path / \"test_participants.tsv\"\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Load participant metadata from TSV files\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Load train and test participants\n",
    "train_data = pd.read_csv(train_filepath, sep=\"\\t\")\n",
    "test_data  = pd.read_csv(test_filepath,  sep=\"\\t\")\n",
    "\n",
    "# Concatenate into one DataFrame\n",
    "all_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n",
    "all_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d014f04e",
   "metadata": {},
   "source": [
    "### FreeSurfer helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b5bec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# FreeSurfer utility functions\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def load_fsdata_raw(participant_id, local_cache_dir=Path.home() / \"cache\"):\n",
    "    \"\"\"\n",
    "    Load the raw FreeSurfer TSV file for a PNC participant.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    participant_id : str or int\n",
    "        RBC participant identifier (without 'sub-' prefix).\n",
    "    local_cache_dir : Path\n",
    "        Local cache directory where RBC files will be stored.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Long-form FreeSurfer stats for the participant.\n",
    "    \"\"\"\n",
    "    local_cache_dir = Path(local_cache_dir)\n",
    "    local_cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    pnc_fspath = RBCPath(\n",
    "        \"rbc://PNC_FreeSurfer/freesurfer\",\n",
    "        local_cache_dir=local_cache_dir\n",
    "    )\n",
    "    subdir = pnc_fspath / f\"sub-{participant_id}\"\n",
    "    tsv_path = subdir / f\"sub-{participant_id}_regionsurfacestats.tsv\"\n",
    "\n",
    "    return pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "\n",
    "\n",
    "def filter_by_atlas(df, atlas_substr):\n",
    "    \"\"\"Filter rows by atlas substring (case-insensitive).\"\"\"\n",
    "    mask = df[\"atlas\"].astype(str).str.contains(atlas_substr, case=False, na=False)\n",
    "    if not mask.any():\n",
    "        available = sorted(df[\"atlas\"].dropna().unique())\n",
    "        raise ValueError(\n",
    "            f\"No atlas rows contained '{atlas_substr}'. \"\n",
    "            f\"Available atlases: {', '.join(available)}\"\n",
    "        )\n",
    "    return df.loc[mask].copy()\n",
    "\n",
    "\n",
    "def select_measure(df, measure):\n",
    "    \"\"\"Select only the relevant columns for a given brain measure.\"\"\"\n",
    "    cols = [\"subject_id\", \"atlas\", \"hemisphere\", \"StructName\", measure]\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "    return df[cols].copy()\n",
    "\n",
    "\n",
    "def sanitize(col):\n",
    "    \"\"\"Sanitize a string for safe use as a column name.\"\"\"\n",
    "    clean = re.sub(r\"[^0-9A-Za-z]+\", \"_\", col)   # replace non-alphanumeric chars\n",
    "    clean = re.sub(r\"_{2,}\", \"_\", clean)         # collapse multiple underscores\n",
    "    return clean.strip(\"_\")                      # strip leading/trailing underscores\n",
    "\n",
    "\n",
    "def pivot(df, measure):\n",
    "    \"\"\"\n",
    "    Pivot long-form FreeSurfer stats into a wide format with one row per subject.\n",
    "    \"\"\"\n",
    "    subj = df[\"subject_id\"].iloc[0]\n",
    "    out = {\"subject_id\": subj}\n",
    "    for _, row in df.iterrows():\n",
    "        raw = f\"{row['hemisphere']}_{row['atlas']}_{row['StructName']}_{measure}\"\n",
    "        col = sanitize(raw)\n",
    "        out[col] = row[measure]\n",
    "    return pd.DataFrame([out])\n",
    "\n",
    "\n",
    "def load_and_pivot_fsdata(participant_id, atlas, measure,\n",
    "                          local_cache_dir=Path.home() / \"cache\"):\n",
    "    \"\"\"\n",
    "    Load, filter, select, and pivot FreeSurfer stats into a wide format.\n",
    "    \"\"\"\n",
    "    fsdata_raw = load_fsdata_raw(participant_id, local_cache_dir)\n",
    "    fsdata_by_atlas = filter_by_atlas(fsdata_raw, atlas)\n",
    "    fsdata_by_measure = select_measure(fsdata_by_atlas, measure)\n",
    "    return pivot(fsdata_by_measure, measure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b489e",
   "metadata": {},
   "source": [
    "### Pick atlas & measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323b6649-3972-4b33-82c5-5aab5dd22988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2cc0be83f24272a4eef79323408da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=1601)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Pick an atlas and brain measure for modeling\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "ATLAS=\"aparc.DKTatlas\"\n",
    "MEASURE=\"ThickAvg\"\n",
    "\n",
    "\n",
    "# We'll display a progress bar `prog` as we go also:\n",
    "from ipywidgets import IntProgress\n",
    "prog = IntProgress(min=0, max=len(all_data))\n",
    "display(prog)\n",
    "\n",
    "demo = [\n",
    "    'age',\n",
    "    'sex',\n",
    "    'race',\n",
    "    'ethnicity',\n",
    "    'bmi',\n",
    "    'handedness',\n",
    "    'participant_education',\n",
    "    'parent_1_education',\n",
    "    'parent_2_education',\n",
    "    'p_factor'\n",
    "]\n",
    "\n",
    "\n",
    "records = []\n",
    "\n",
    "for row in all_data.itertuples(index=False):\n",
    "    # start record with participant_id + all demo vars\n",
    "    rec = {col: getattr(row, col) for col in ['participant_id'] + demo}\n",
    "\n",
    "    # try to load & pivot; if successful, merge in all FS cols\n",
    "    try:\n",
    "        freesurfer = (\n",
    "                        load_and_pivot_fsdata(\n",
    "                            participant_id=rec['participant_id'],\n",
    "                            atlas=ATLAS,\n",
    "                            measure=MEASURE,\n",
    "                            local_cache_dir=Path.home()/\"cache\"\n",
    "                        )\n",
    "            .drop(columns='subject_id')  # remove duplicate ID col\n",
    "            .iloc[0]\n",
    "            .to_dict()\n",
    "        )\n",
    "        rec.update(freesurfer)\n",
    "    except (FileNotFoundError, ValueError):\n",
    "        # leave rec with only ID+demo if FS data is missing/blank\n",
    "        pass\n",
    "\n",
    "    records.append(rec)\n",
    "    prog.value += 1\n",
    "\n",
    "all_demo_and_brain = pd.DataFrame(records)\n",
    "\n",
    "# split into train/test\n",
    "train_vars = all_demo_and_brain[all_demo_and_brain['p_factor'].notna()]\n",
    "test_vars  = all_demo_and_brain[all_demo_and_brain['p_factor'].isna()]\n",
    "\n",
    "all_demo_and_brain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d6e1c-aa1f-4ac5-a35c-da5b2d2eb300",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "### Remove uninformative subjects (with plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf7caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Remove subjects at the minimum p_factor value and plot distributions\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Plot histogram of p_factor for all training subjects\n",
    "train_data[\"p_factor\"].hist(bins=100)\n",
    "\n",
    "# Print minimum value and its count\n",
    "print(\"Minimum p_factor:\", train_data[\"p_factor\"].min())\n",
    "print(\"Number of subjects with min value:\",\n",
    "      train_data[\"p_factor\"].value_counts()[train_data[\"p_factor\"].min()])\n",
    "\n",
    "# Remove subjects with minimum p_factor (to avoid bias in modeling)\n",
    "min_val_idx = train_data[\"p_factor\"] == train_data[\"p_factor\"].min()\n",
    "removed_train_data = train_data[min_val_idx].copy()\n",
    "clean_train_data   = train_data[~min_val_idx]\n",
    "\n",
    "# Plot histogram after cleaning\n",
    "clean_train_data[\"p_factor\"].hist()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
