{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3270dc9c",
   "metadata": {},
   "source": [
    "# RBC Loading & Modeling Template\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "\n",
    "1. Load participant metadata from the Reproducible Brain Charts (RBC).  \n",
    "2. Retrieve FreeSurfer region-surface stats for participants.  \n",
    "3. Clean and filter data.  \n",
    "4. Plot simple histograms of the target variable.  \n",
    "5. Prepare a subset of subjects and features for modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1e3b6",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c98db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Imports\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "from pathlib import Path             # for handling filesystem paths\n",
    "import re                            # for regex string cleaning\n",
    "import numpy as np                   # for numeric operations\n",
    "import pandas as pd                  # for tabular data handling\n",
    "from rbclib import RBCPath           # RBC-specific path handling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac25bd9c",
   "metadata": {},
   "source": [
    "### Data paths & participant metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b4b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Paths to the RBC data\n",
    "# ---------------------------------------------------------------------------\n",
    "rbcdata_path = Path(\"/home/jovyan/shared/data/RBC\")\n",
    "train_filepath = rbcdata_path / \"train_participants.tsv\"\n",
    "test_filepath  = rbcdata_path / \"test_participants.tsv\"\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Load participant metadata from TSV files\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Load train and test participants\n",
    "train_data = pd.read_csv(train_filepath, sep=\"\\t\")\n",
    "test_data  = pd.read_csv(test_filepath,  sep=\"\\t\")\n",
    "\n",
    "# Concatenate into one DataFrame\n",
    "all_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n",
    "all_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d014f04e",
   "metadata": {},
   "source": [
    "### FreeSurfer helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5bec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# FreeSurfer utility functions\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def load_fsdata_raw(participant_id, local_cache_dir=Path.home() / \"cache\"):\n",
    "    \"\"\"\n",
    "    Load the raw FreeSurfer TSV file for a PNC participant.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    participant_id : str or int\n",
    "        RBC participant identifier (without 'sub-' prefix).\n",
    "    local_cache_dir : Path\n",
    "        Local cache directory where RBC files will be stored.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Long-form FreeSurfer stats for the participant.\n",
    "    \"\"\"\n",
    "    local_cache_dir = Path(local_cache_dir)\n",
    "    local_cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    pnc_fspath = RBCPath(\n",
    "        \"rbc://PNC_FreeSurfer/freesurfer\",\n",
    "        local_cache_dir=local_cache_dir\n",
    "    )\n",
    "    subdir = pnc_fspath / f\"sub-{participant_id}\"\n",
    "    tsv_path = subdir / f\"sub-{participant_id}_regionsurfacestats.tsv\"\n",
    "\n",
    "    return pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "\n",
    "\n",
    "def filter_by_atlas(df, atlas_substr):\n",
    "    \"\"\"Filter rows by atlas substring (case-insensitive).\"\"\"\n",
    "    mask = df[\"atlas\"].astype(str).str.contains(atlas_substr, case=False, na=False)\n",
    "    if not mask.any():\n",
    "        available = sorted(df[\"atlas\"].dropna().unique())\n",
    "        raise ValueError(\n",
    "            f\"No atlas rows contained '{atlas_substr}'. \"\n",
    "            f\"Available atlases: {', '.join(available)}\"\n",
    "        )\n",
    "    return df.loc[mask].copy()\n",
    "\n",
    "\n",
    "def select_measure(df, measure):\n",
    "    \"\"\"Select only the relevant columns for a given brain measure.\"\"\"\n",
    "    cols = [\"subject_id\", \"atlas\", \"hemisphere\", \"StructName\", measure]\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "    return df[cols].copy()\n",
    "\n",
    "\n",
    "def sanitize(col):\n",
    "    \"\"\"Sanitize a string for safe use as a column name.\"\"\"\n",
    "    clean = re.sub(r\"[^0-9A-Za-z]+\", \"_\", col)   # replace non-alphanumeric chars\n",
    "    clean = re.sub(r\"_{2,}\", \"_\", clean)         # collapse multiple underscores\n",
    "    return clean.strip(\"_\")                      # strip leading/trailing underscores\n",
    "\n",
    "\n",
    "def pivot(df, measure):\n",
    "    \"\"\"\n",
    "    Pivot long-form FreeSurfer stats into a wide format with one row per subject.\n",
    "    \"\"\"\n",
    "    subj = df[\"subject_id\"].iloc[0]\n",
    "    out = {\"subject_id\": subj}\n",
    "    for _, row in df.iterrows():\n",
    "        raw = f\"{row['hemisphere']}_{row['atlas']}_{row['StructName']}_{measure}\"\n",
    "        col = sanitize(raw)\n",
    "        out[col] = row[measure]\n",
    "    return pd.DataFrame([out])\n",
    "\n",
    "\n",
    "def load_and_pivot_fsdata(participant_id, atlas, measure,\n",
    "                          local_cache_dir=Path.home() / \"cache\"):\n",
    "    \"\"\"\n",
    "    Load, filter, select, and pivot FreeSurfer stats into a wide format.\n",
    "    \"\"\"\n",
    "    fsdata_raw = load_fsdata_raw(participant_id, local_cache_dir)\n",
    "    fsdata_by_atlas = filter_by_atlas(fsdata_raw, atlas)\n",
    "    fsdata_by_measure = select_measure(fsdata_by_atlas, measure)\n",
    "    return pivot(fsdata_by_measure, measure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18f6f13",
   "metadata": {},
   "source": [
    "### Remove uninformative subjects (with plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf7caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Remove subjects at the minimum p_factor value and plot distributions\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Plot histogram of p_factor for all training subjects\n",
    "train_data[\"p_factor\"].hist(bins=100)\n",
    "\n",
    "# Print minimum value and its count\n",
    "print(\"Minimum p_factor:\", train_data[\"p_factor\"].min())\n",
    "print(\"Number of subjects with min value:\",\n",
    "      train_data[\"p_factor\"].value_counts()[train_data[\"p_factor\"].min()])\n",
    "\n",
    "# Remove subjects with minimum p_factor (to avoid bias in modeling)\n",
    "min_val_idx = train_data[\"p_factor\"] == train_data[\"p_factor\"].min()\n",
    "removed_train_data = train_data[min_val_idx].copy()\n",
    "clean_train_data   = train_data[~min_val_idx]\n",
    "\n",
    "# Plot histogram after cleaning\n",
    "clean_train_data[\"p_factor\"].hist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e36cc1a",
   "metadata": {},
   "source": [
    "### Sample a small subset of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4b709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Work with a small subset of subjects (for speed)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "clean_train_data = clean_train_data.reset_index(drop=True)\n",
    "num_subjects = 5\n",
    "idx_max = clean_train_data.shape[0]\n",
    "\n",
    "# Randomly select subject indices\n",
    "rand_ii = np.random.randint(low=0, high=idx_max, size=num_subjects)\n",
    "rand_subjects = clean_train_data.loc[rand_ii, \"participant_id\"].values\n",
    "\n",
    "print(\"Randomly selected subjects:\", rand_subjects)\n",
    "\n",
    "# Load FreeSurfer stats for selected subjects\n",
    "dfs = []\n",
    "for subject_id in rand_subjects:\n",
    "    df = load_fsdata_raw(subject_id)\n",
    "    dfs.append(df)\n",
    "\n",
    "training_subset = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "training_subset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b489e",
   "metadata": {},
   "source": [
    "### Pick atlas & measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb6cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Pick an atlas and brain measure for modeling\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "print(\"Atlases:\", training_subset[\"atlas\"].unique())\n",
    "print(\"Available columns (measures):\", training_subset.columns.tolist())\n",
    "\n",
    "# Example selection\n",
    "atlas = \"aparc.DKTatlas\"\n",
    "measure = \"GrayVol\"\n",
    "\n",
    "fsdata_by_atlas = filter_by_atlas(training_subset, atlas)\n",
    "fsdata_by_measure = select_measure(fsdata_by_atlas, measure)\n",
    "\n",
    "fsdata_by_measure.head()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
